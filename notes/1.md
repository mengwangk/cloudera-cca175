CCA175 - 1

Installation on Mac Sierra
https://www.slideshare.net/SunilkumarMohanty3/install-apache-hadoop-on-mac-os-sierra-76275019

Packages
https://www.cloudera.com/documentation/enterprise/release-notes/topics/cdh_vd_cdh_package_tarball.html

Software
- Hadoop
- Sqoop
- MySQL
- Spark
- Impala
- Hue
- 

https://www.aws.training/transcript/curriculumplayer?transcriptId=ofeb093-6U-F24xUkWtuzA2

Module 1
- Introduction to Big Data
    - Big Data solutions
    - 3 concerns
        - Volume
        - Velocity
        - Variety
    - Factors affecting ability to extract value
    - Want to go beyond current value
    - Data rich information poor
- Architectural components
    - Parallelism - distribute the load, larger data sets, faster computation
    - Hadoop - big data standard
        - Not a database
        - Scalable data storage and batch processing framework
        - Ingests, processes, aggregates external data
        - Results can be exported
        - Hadoop Commons, HDFS, YARN, MapReduce
    - HDFS
        - Name node, Data node
    - YARN - yet another resource negotiator
    - Big Data job types
        - MapReduce
            - Parallel processing of large data sets
            - 2 phases
                - Map
                - Reduce
            - Also
                - Partition
                - Shuffle
                - Sort
        - Hive
            - Data warehouse infrastructure
            - Provides HQL
            - Provides
                - Summarisation
                - Analysis
                - Ad hoc querying
        - PIG
            - Programming environment for data tasks
            - Queries, data manipulation
            - Combine SQL/MR
    - Use Cases
        - Retail, Power Grid, Bank Risk
    - Knowledge Check


Module 2 - Database Architectures
- RDS
- NoSQL
- DataWarehouse, DataMart (smaller compared to DateWarehouse)


Module 3 - Hadoop and MapReduce
- Hadoop
    - Process large database via distributed computing
    - Hadoop 1.X and 2.X
        - Distributed data storage - HDFS
        - 2.X - YARN - resource mgmt, data processing - MapReduce
    - 2.X - additional passive name node. No single point of failure
- MapReduce
    - Parallel processing framework
    - Works with Hadoop
    - Scaled-out architecture
    - Processing of structured and unstructured data
    - Runs on large clusters of commodity hardware
    - Fault tolerant
    - Optimised scheduling
    - Flexibility for developers
    - Interoperates with tools like Hive and Pig
    - Operates on key/value pair
    - Accept key/value pairs as input
    - Produces key/value pairs as output
    - MapReduce Joins
        - Joins
            - Combines tables or datasets
        - Benefits
            - Provide insights and analysis
        - Map side join, reduce side join, distributed cache
    - MapReduce Combiner and Partitioner
        - Combiner
            - Optional mini reducer
            - Runs in memory - after map:before reducer
            - Optimize bandwidth
        - Partitioner
            - Defines how keys are assigned to reducers
            - Determines which reducer receives which key-value pair
    - MapReduce interfaces
    - MapReduce Architecture: Execution
        - Java JAR and streaming API
        - Java JAR command
            - Jar file specified with input and output path
        - Streaming API
            - Execute MapReduce jobs written in other languages
    - MapReduce: Concepts in Action
    - 


Module 4 - Hive and Pig
- Hive
    - Data warehousing architecture
    - Uses MapReduce and HDFS
    - Provides HQL
    - Functions
        - Querying/analyzing
        - Managed unstructured data as structured
        - Leverage SQL skills
    - Why
        - Report generation
        - Easy summarisation
        - Analysis of large volumes of data
        - Adhoc querying
    - Hadoop with Hive vs RDMS
        - Built for different purposes and has their pros and cons
        - Not alternative for RDBMS
        - Can co-exists
        - Hive - petabytes of unstructured, semi-structured, and structured data
    - Hive components
        - JDBC, ODBC, Web UI, CLI, Driver (compiler, optimiser, executore), Metastore, Thrift Server
    - Hive workflow example
    - Hive Interaction via CLI
        - Most common way to interact with Hive
        - Issue DDL and metadata exploration commands
    - Hive architecture - data organization
        - Database, Tables, Partitions, Buckets
        - Buckets - avoid too many partitions, file in directory
    - Hive indexes - compaction and bitmap
    - Hive metastore
        - Central metadata repository - partitions, tables, and table locations, schema, columns and column types
- Pig
    - Scripting language for analysing large datasets
    - Open source high level programming environment
    - Appeal those familiar with scripting languages and SQL
    - Used by programmers and researchers
    - Why use it
        - Simplifies complex data analysis on large datasets
        - Similar to SQL query
        - No Java required
    - Pig architecture
    - Pig overview - when to use
        - Pipeline data
        - App needs debugging on regular basis
        - Donâ€™t know Java
        - Rapid dev and testing
        - Integrative data processing
    - Pig Latin: Features
        - Multi query approach
        - Operators - join, sort, filter, etc
        - Nested data types: tuples, bags, and maps
        - Automatic optimisation
        - user defined functions (UDF)
        - Structured and unstructured data
    - Pig Latin: Identifiers
    - Simple Pig Latin data types
        - Int, long, float, double, byte array, boolean, char array
    - Complex Pig Latin Data Types
        - Data Atom, Tuple, Data Bag, Data Map
    - Pig Latin: Relations
    - Pig Latin: Schemas
    - Pig Latin: Input Data Flow
    - Pig Latin: Output Data Flow
    - Pig Latin Architecture: Running Pig Programs
    - Pig Latin: User Defined Functions
    - Pig Joins
    - 










